"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ baseline –º–æ–¥–µ–ª–µ–π.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å –ø—Ä–æ–µ–∫—Ç–æ–º Terrazite AI –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ —Ä–µ—Ü–µ–ø—Ç–æ–≤ –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏.
"""
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union
import matplotlib.pyplot as plt
import seaborn as sns

from ..utils.config import config
from ..utils.logger import setup_logger

logger = setup_logger(__name__)


class SimpleAggregateClassifier:
    """
    –ü—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–µ—Ä—Ä–∞–∑–∏—Ç–æ–≤–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º.
    –ú–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ baseline –æ—Ü–µ–Ω–∫–∏.
    """
    
    def __init__(self, 
                 n_estimators: int = 100,
                 random_state: int = 42,
                 typical_components: Optional[Dict[str, List[str]]] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        
        Args:
            n_estimators: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ RandomForest
            random_state: –°–µ–º—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
            typical_components: –°–ª–æ–≤–∞—Ä—å —Ç–∏–ø–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        self.n_estimators = n_estimators
        self.random_state = random_state
        
        # –ú–æ–¥–µ–ª—å
        self.model = RandomForestClassifier(
            n_estimators=n_estimators,
            random_state=random_state,
            n_jobs=-1,
            class_weight='balanced'
        )
        
        # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        self.label_encoder = LabelEncoder()
        self.scaler = StandardScaler()
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ
        self.feature_names = []
        self.classes_ = []
        self.category_info = {}
        
        # –¢–∏–ø–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        self.typical_components = typical_components or self._load_default_components()
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω SimpleAggregateClassifier —Å {n_estimators} –¥–µ—Ä–µ–≤—å—è–º–∏")
    
    def _load_default_components(self) -> Dict[str, List[str]]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–ø–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å –∫–∞—Ç–µ–≥–æ—Ä–∏—è -> —Å–ø–∏—Å–æ–∫ —Ç–∏–ø–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            components_by_category = {}
            
            for category in config.data.recipe_categories:
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                category_info = config.get_category_info(category)
                
                # –ë–µ—Ä–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ –∏–∑ –≥—Ä—É–ø–ø
                typical_comps = []
                
                # –î–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤—ã–±–∏—Ä–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
                if category == '–¢–µ—Ä—Ä–∞–∑–∏—Ç':
                    typical_comps = ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–ü–µ—Å–æ–∫ –ª—É–∂—Å–∫–∏–π —Ñ—Ä.0-0,63–º–º, –∫–≥']
                elif category == '–®–æ–≤–Ω—ã–π':
                    typical_comps = ['–¶–µ–º–µ–Ω—Ç —Å–µ—Ä—ã–π –ü–¶500, –∫–≥', '–ú–∏–∫—Ä–æ–∫–∞–ª—å—Ü–∏—Ç –ú–ö100 —Ñ—Ä.0,1 –º–º, –∫–≥']
                elif category == '–ú–∞—Å—Ç–∏–∫–∞':
                    typical_comps = ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–î–æ–ª–æ–º–∏—Ç–æ–≤–∞—è –º—É–∫–∞, –∫–≥']
                elif category == '–¢–µ—Ä—Ä–∞—Ü—Ü–æ':
                    typical_comps = ['–ú—Ä–∞–º–æ—Ä –±–µ–ª—ã–π —Ñ—Ä.0,5-1,0 –º–º, –∫–≥', '–ü–∏–≥–º–µ–Ω—Ç –∂–µ–ª—Ç—ã–π S313, –∫–≥']
                elif category == '–†–µ—Ç—É—à—å':
                    typical_comps = ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–†–ü–ü –ü–æ–ª–∏–ø–ª–∞—Å—Ç (Dairen 1400, Vinnapas 4023, Vinavil 5603, WWJF - 8020, –û–†–ü 7085, Elotex) –∫–≥']
                
                components_by_category[category] = typical_comps
            
            logger.info("–¢–∏–ø–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return components_by_category
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            
            # –ó–∞–≥–ª—É—à–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            return {
                '–¢–µ—Ä—Ä–∞–∑–∏—Ç': ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–ü–µ—Å–æ–∫ –ª—É–∂—Å–∫–∏–π'],
                '–®–æ–≤–Ω—ã–π': ['–¶–µ–º–µ–Ω—Ç —Å–µ—Ä—ã–π –ü–¶500, –∫–≥', '–ú–∏–∫—Ä–æ–∫–∞–ª—å—Ü–∏—Ç'],
                '–ú–∞—Å—Ç–∏–∫–∞': ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–î–æ–ª–æ–º–∏—Ç–æ–≤–∞—è –º—É–∫–∞, –∫–≥'],
                '–¢–µ—Ä—Ä–∞—Ü—Ü–æ': ['–ú—Ä–∞–º–æ—Ä –±–µ–ª—ã–π', '–ü–∏–≥–º–µ–Ω—Ç—ã'],
                '–†–µ—Ç—É—à—å': ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–†–ü–ü –ü–æ–ª–∏–ø–ª–∞—Å—Ç']
            }
    
    def extract_color_histogram(self, 
                               image: np.ndarray, 
                               bins: int = 32) -> np.ndarray:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ü–≤–µ—Ç–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ numpy array [H, W, 3]
            bins: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏–Ω–æ–≤ –≤ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–µ
            
        Returns:
            –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if len(image.shape) != 3 or image.shape[2] != 3:
                logger.warning(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.shape}")
                # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å
                if len(image.shape) == 3 and image.shape[2] > 3:
                    image = image[:, :, :3]
                elif len(image.shape) == 2:
                    image = np.stack([image, image, image], axis=2)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–∞–Ω–∞–ª—ã RGB
            channels = []
            for i in range(3):
                channel = image[:, :, i]
                hist, _ = np.histogram(channel, bins=bins, range=(0, 256))
                channels.append(hist)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            features = np.concatenate(channels)
            features = features / (image.shape[0] * image.shape[1])  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –ø–∏–∫—Å–µ–ª—è–º
            
            return features
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            return np.zeros(3 * bins)
    
    def extract_component_features(self, 
                                 components_dict: Dict[str, float]) -> np.ndarray:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        
        Args:
            components_dict: –°–ª–æ–≤–∞—Ä—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç -> –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–≥
            
        Returns:
            –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            all_components = []
            for group_components in config.data.component_groups.values():
                all_components.extend(group_components)
            
            # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
            features = np.zeros(len(all_components))
            
            for i, component in enumerate(all_components):
                if component in components_dict:
                    features[i] = components_dict[component]
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            total = features.sum()
            if total > 0:
                features = features / total * 1000  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
            
            return features
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
            return np.zeros(100)  # –í–µ–∫—Ç–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def combine_features(self, 
                        image_features: np.ndarray,
                        component_features: np.ndarray) -> np.ndarray:
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        
        Args:
            image_features: –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            component_features: –ü—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        image_weight = 0.6  # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        component_weight = 0.4
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if image_features.max() > 0:
            image_features = image_features / image_features.max()
        
        if component_features.max() > 0:
            component_features = component_features / component_features.max()
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        combined = np.concatenate([
            image_features * image_weight,
            component_features * component_weight
        ])
        
        return combined
    
    def fit(self, 
           X_images: List[np.ndarray], 
           X_components: List[Dict[str, float]],
           y: List[str]) -> 'SimpleAggregateClassifier':
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
        
        Args:
            X_images: –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            X_components: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            y: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            
        Returns:
            self
        """
        logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_features = []
        for img, comp in zip(X_images, X_components):
            img_features = self.extract_color_histogram(img)
            comp_features = self.extract_component_features(comp)
            combined = self.combine_features(img_features, comp_features)
            X_features.append(combined)
        
        X_features = np.array(X_features)
        self.feature_names = [f'feature_{i}' for i in range(X_features.shape[1])]
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        y_encoded = self.label_encoder.fit_transform(y)
        self.classes_ = self.label_encoder.classes_
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_features = self.scaler.fit_transform(X_features)
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        logger.info(f"–û–±—É—á–µ–Ω–∏–µ RandomForest –Ω–∞ {len(X_features)} –æ–±—Ä–∞–∑—Ü–∞—Ö...")
        self.model.fit(X_features, y_encoded)
        
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        cv_scores = cross_val_score(self.model, X_features, y_encoded, cv=5)
        logger.info(f"–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (5-fold): {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Å–∞—Ö
        self.category_info = {}
        for i, class_name in enumerate(self.classes_):
            class_indices = np.where(y_encoded == i)[0]
            self.category_info[class_name] = {
                'count': len(class_indices),
                'typical_components': self.typical_components.get(class_name, [])
            }
        
        logger.info(f"–û–±—É—á–µ–Ω–æ. –ö–ª–∞—Å—Å—ã: {list(self.classes_)}")
        
        return self
    
    def fit_from_dataframe(self, 
                          df: pd.DataFrame,
                          image_column: str = 'image',
                          component_columns: List[str] = None) -> 'SimpleAggregateClassifier':
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ DataFrame
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            image_column: –ö–æ–ª–æ–Ω–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            component_columns: –ö–æ–ª–æ–Ω–∫–∏ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
            
        Returns:
            self
        """
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_images = []
        X_components = []
        y = []
        
        for _, row in df.iterrows():
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if image_column in row:
                X_images.append(row[image_column])
            
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            components_dict = {}
            if component_columns:
                for col in component_columns:
                    if col in row and pd.notna(row[col]):
                        components_dict[col] = float(row[col])
            
            X_components.append(components_dict)
            
            # –ú–µ—Ç–∫–∞ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'category')
            if 'category' in row:
                y.append(str(row['category']))
        
        return self.fit(X_images, X_components, y)
    
    def predict(self, 
               X_images: Union[np.ndarray, List[np.ndarray]],
               X_components: Optional[List[Dict[str, float]]] = None) -> np.ndarray:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        Args:
            X_images: –û–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            X_components: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        """
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if isinstance(X_images, np.ndarray) and len(X_images.shape) == 3:
            X_images = [X_images]
        
        if X_components is None:
            X_components = [{} for _ in range(len(X_images))]
        elif isinstance(X_components, dict):
            X_components = [X_components]
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_features = []
        for img, comp in zip(X_images, X_components):
            img_features = self.extract_color_histogram(img)
            comp_features = self.extract_component_features(comp)
            combined = self.combine_features(img_features, comp_features)
            X_features.append(combined)
        
        X_features = np.array(X_features)
        X_features = self.scaler.transform(X_features)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        y_encoded = self.model.predict(X_features)
        y = self.label_encoder.inverse_transform(y_encoded)
        
        return y
    
    def predict_with_components(self, 
                               image: np.ndarray,
                               components: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
        
        Args:
            image: –í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            components: –°–ª–æ–≤–∞—Ä—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        """
        prediction = self.predict([image], [components] if components else None)[0]
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        if hasattr(self.model, 'predict_proba'):
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            img_features = self.extract_color_histogram(image)
            comp_features = self.extract_component_features(components or {})
            combined = self.combine_features(img_features, comp_features)
            combined = self.scaler.transform([combined])
            
            probs = self.model.predict_proba(combined)[0]
            confidence = max(probs)
            probabilities = {
                cls: float(prob) 
                for cls, prob in zip(self.classes_, probs)
            }
        else:
            confidence = 1.0
            probabilities = {}
        
        # –¢–∏–ø–∏—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        typical_components = self._get_typical_components(prediction)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        category_info = self.category_info.get(prediction, {})
        
        return {
            'category': prediction,
            'confidence': float(confidence),
            'probabilities': probabilities,
            'typical_components': typical_components,
            'category_info': category_info,
            'model_type': 'RandomForest',
            'components_used': bool(components)
        }
    
    def predict_proba(self, 
                     X_images: Union[np.ndarray, List[np.ndarray]],
                     X_components: Optional[List[Dict[str, float]]] = None) -> np.ndarray:
        """
        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        
        Args:
            X_images: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            X_components: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            
        Returns:
            –ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π [n_samples, n_classes]
        """
        if isinstance(X_images, np.ndarray) and len(X_images.shape) == 3:
            X_images = [X_images]
        
        if X_components is None:
            X_components = [{} for _ in range(len(X_images))]
        elif isinstance(X_components, dict):
            X_components = [X_components]
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_features = []
        for img, comp in zip(X_images, X_components):
            img_features = self.extract_color_histogram(img)
            comp_features = self.extract_component_features(comp)
            combined = self.combine_features(img_features, comp_features)
            X_features.append(combined)
        
        X_features = np.array(X_features)
        X_features = self.scaler.transform(X_features)
        
        return self.model.predict_proba(X_features)
    
    def evaluate(self, 
                X_images: List[np.ndarray],
                X_components: List[Dict[str, float]],
                y: List[str],
                plot_results: bool = True) -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        
        Args:
            X_images: –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            X_components: –¢–µ—Å—Ç–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            y: –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            plot_results: –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
        
        y_pred = self.predict(X_images, X_components)
        accuracy = accuracy_score(y, y_pred)
        
        # –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
        report = classification_report(y, y_pred, output_dict=True)
        
        logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
        logger.info("\n–û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
        for cls, metrics in report.items():
            if cls not in ['accuracy', 'macro avg', 'weighted avg']:
                logger.info(f"  {cls}: precision={metrics['precision']:.3f}, "
                          f"recall={metrics['recall']:.3f}, f1={metrics['f1-score']:.3f}")
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(y, y_pred, labels=self.classes_)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        if plot_results:
            self.plot_confusion_matrix(cm, self.classes_)
        
        return {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm.tolist(),
            'predictions': y_pred.tolist(),
            'true_labels': y
        }
    
    def plot_confusion_matrix(self, 
                             cm: np.ndarray,
                             class_names: List[str],
                             save_path: Optional[str] = None):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
        
        Args:
            cm: –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
            class_names: –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        plt.figure(figsize=(10, 8))
        
        # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names
        )
        
        plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ SimpleAggregateClassifier')
        plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
        plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
        plt.tight_layout()
        
        if save_path:
            Path(save_path).parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
        
        plt.show()
        plt.close()
    
    def get_feature_importance(self) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Returns:
            DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if not hasattr(self.model, 'feature_importances_'):
            logger.warning("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return pd.DataFrame()
        
        importance = self.model.feature_importances_
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importance
        })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–∞–∂–Ω–æ—Å—Ç–∏
        df = df.sort_values('importance', ascending=False)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
        df['feature_type'] = df['feature'].apply(
            lambda x: 'image' if x.startswith('feature_') and int(x.split('_')[1]) < 96 
            else 'component'
        )
        
        logger.info("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        logger.info(f"  –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df)}")
        logger.info(f"  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {df[df['feature_type'] == 'image']['importance'].sum():.3f}")
        logger.info(f"  –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {df[df['feature_type'] == 'component']['importance'].sum():.3f}")
        
        return df
    
    def _get_typical_components(self, category: str) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∏–ø–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        
        Args:
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ä–µ—Ü–µ–ø—Ç–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–∏–ø–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        """
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
        try:
            if hasattr(self, 'typical_components') and category in self.typical_components:
                return self.typical_components[category]
        except:
            pass
        
        # –ó–∞–≥–ª—É—à–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        components_by_category = {
            '–¢–µ—Ä—Ä–∞–∑–∏—Ç': ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–ü–µ—Å–æ–∫ –ª—É–∂—Å–∫–∏–π —Ñ—Ä.0-0,63–º–º, –∫–≥'],
            '–®–æ–≤–Ω—ã–π': ['–¶–µ–º–µ–Ω—Ç —Å–µ—Ä—ã–π –ü–¶500, –∫–≥', '–ú–∏–∫—Ä–æ–∫–∞–ª—å—Ü–∏—Ç –ú–ö100 —Ñ—Ä.0,1 –º–º, –∫–≥'],
            '–ú–∞—Å—Ç–∏–∫–∞': ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–î–æ–ª–æ–º–∏—Ç–æ–≤–∞—è –º—É–∫–∞, –∫–≥'],
            '–¢–µ—Ä—Ä–∞—Ü—Ü–æ': ['–ú—Ä–∞–º–æ—Ä –±–µ–ª—ã–π —Ñ—Ä.0,5-1,0 –º–º, –∫–≥', '–ü–∏–≥–º–µ–Ω—Ç –∂–µ–ª—Ç—ã–π S313, –∫–≥'],
            '–†–µ—Ç—É—à—å': ['–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500', '–†–ü–ü –ü–æ–ª–∏–ø–ª–∞—Å—Ç (Dairen 1400, Vinnapas 4023, Vinavil 5603, WWJF - 8020, –û–†–ü 7085, Elotex) –∫–≥']
        }
        
        return components_by_category.get(category, [])
    
    def save(self, path: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        
        Args:
            path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        save_data = {
            'model': self.model,
            'label_encoder': self.label_encoder,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'classes': self.classes_,
            'category_info': self.category_info,
            'typical_components': self.typical_components,
            'config': {
                'n_estimators': self.n_estimators,
                'random_state': self.random_state
            }
        }
        
        joblib.dump(save_data, path)
        logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {path}")
    
    def load(self, path: str) -> 'SimpleAggregateClassifier':
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        
        Args:
            path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
            
        Returns:
            self
        """
        if not Path(path).exists():
            raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        
        data = joblib.load(path)
        
        self.model = data['model']
        self.label_encoder = data['label_encoder']
        self.scaler = data['scaler']
        self.feature_names = data['feature_names']
        self.classes_ = data['classes']
        self.category_info = data.get('category_info', {})
        self.typical_components = data.get('typical_components', {})
        
        if 'config' in data:
            self.n_estimators = data['config'].get('n_estimators', 100)
            self.random_state = data['config'].get('random_state', 42)
        
        logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {path}")
        logger.info(f"–ö–ª–∞—Å—Å—ã: {list(self.classes_)}")
        
        return self
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª–∏
        """
        info = {
            'model_type': 'SimpleAggregateClassifier (RandomForest)',
            'n_estimators': self.n_estimators,
            'classes': list(self.classes_),
            'num_classes': len(self.classes_),
            'num_features': len(self.feature_names),
            'category_info': self.category_info,
            'typical_components': self.typical_components,
            'random_state': self.random_state
        }
        
        return info


def create_simple_classifier(n_estimators: int = 100, 
                           random_state: int = 42) -> SimpleAggregateClassifier:
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    
    Args:
        n_estimators: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤
        random_state: –°–µ–º—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        
    Returns:
        SimpleAggregateClassifier
    """
    return SimpleAggregateClassifier(
        n_estimators=n_estimators,
        random_state=random_state
    )


def test_classifier():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SimpleAggregateClassifier")
    logger.info("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    num_samples = 100
    
    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    images = [
        np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8) 
        for _ in range(num_samples)
    ]
    
    # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    components = []
    for _ in range(num_samples):
        comp_dict = {
            '–¶–µ–º–µ–Ω—Ç –±–µ–ª—ã–π –ü–¶500': np.random.uniform(100, 300),
            '–ü–µ—Å–æ–∫ –ª—É–∂—Å–∫–∏–π —Ñ—Ä.0-0,63–º–º, –∫–≥': np.random.uniform(200, 500)
        }
        components.append(comp_dict)
    
    # –ú–µ—Ç–∫–∏ (5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
    categories = ['–¢–µ—Ä—Ä–∞–∑–∏—Ç', '–®–æ–≤–Ω—ã–π', '–ú–∞—Å—Ç–∏–∫–∞', '–¢–µ—Ä—Ä–∞—Ü—Ü–æ', '–†–µ—Ç—É—à—å']
    labels = np.random.choice(categories, size=num_samples)
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    clf = SimpleAggregateClassifier(n_estimators=50, random_state=42)
    
    try:
        clf.fit(images, components, labels)
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ
        test_images = images[:10]
        test_components = components[:10]
        test_labels = labels[:10]
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predictions = clf.predict(test_images, test_components)
        logger.info(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predictions}")
        
        # –û—Ü–µ–Ω–∫–∞
        metrics = clf.evaluate(test_images, test_components, test_labels, plot_results=False)
        logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å: {metrics['accuracy']:.2%}")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
        single_prediction = clf.predict_with_components(test_images[0], test_components[0])
        logger.info(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏: {single_prediction}")
        
        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = clf.get_feature_importance()
        if not feature_importance.empty:
            logger.info(f"–¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
            for _, row in feature_importance.head().iterrows():
                logger.info(f"  {row['feature']}: {row['importance']:.4f}")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        model_info = clf.get_model_info()
        logger.info(f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
        logger.info(f"  –¢–∏–ø: {model_info['model_type']}")
        logger.info(f"  –ö–ª–∞—Å—Å—ã: {model_info['num_classes']}")
        logger.info(f"  –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {model_info['num_features']}")
        
        logger.info("\n‚úÖ SimpleAggregateClassifier –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        
        return clf
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
    clf = test_classifier()
    
    if clf:
        print("\n–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
        print("1. clf = SimpleAggregateClassifier(n_estimators=100)")
        print("2. clf.fit(images, components, labels)")
        print("3. prediction = clf.predict(test_images, test_components)")
        print("4. detailed = clf.predict_with_components(image, components)")
        print("5. clf.save('models/simple_classifier.joblib')")
