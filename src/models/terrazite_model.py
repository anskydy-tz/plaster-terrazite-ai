"""
–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ—Ü–µ–ø—Ç–∞ —Ç–µ—Ä—Ä–∞–∑–∏—Ç–æ–≤–æ–π —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏
–ú–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è –º–æ–¥–µ–ª—å: —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è —Ç–∏–ø–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model
from typing import Tuple, Dict, List, Optional
import numpy as np
import logging

logger = logging.getLogger(__name__)


class TerraziteRecipeModel:
    """
    –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ—Ü–µ–ø—Ç–∞ —Ç–µ—Ä—Ä–∞–∑–∏—Ç–æ–≤–æ–π —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - –í—Ö–æ–¥: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 224x224x3
    - Backbone: EfficientNet-B0 (–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π)
    - –í—ã—Ö–æ–¥ 1: —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è 10+ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–µ—Ü–µ–ø—Ç–∞
    - –í—ã—Ö–æ–¥ 2: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –º–∏–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è
    """
    
    def __init__(
        self,
        input_shape: Tuple[int, int, int] = (224, 224, 3),
        num_regression_outputs: int = 15,
        num_classes: int = 5,
        dropout_rate: float = 0.3,
        learning_rate: float = 0.001
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            input_shape: –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤—ã—Å–æ—Ç–∞, —à–∏—Ä–∏–Ω–∞, –∫–∞–Ω–∞–ª—ã)
            num_regression_outputs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä–µ—Ü–µ–ø—Ç–∞)
            num_classes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            dropout_rate: Rate –¥–ª—è —Å–ª–æ–µ–≤ Dropout
            learning_rate: –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        """
        self.input_shape = input_shape
        self.num_regression_outputs = num_regression_outputs
        self.num_classes = num_classes
        self.dropout_rate = dropout_rate
        self.learning_rate = learning_rate
        self.model = None
        self.history = None
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:")
        logger.info(f"  input_shape: {input_shape}")
        logger.info(f"  regression_outputs: {num_regression_outputs}")
        logger.info(f"  classes: {num_classes}")
    
    def build_model(self) -> Model:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
        
        Returns:
            –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Keras
        """
        # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        inputs = layers.Input(shape=self.input_shape)
        
        # –ë–∞–∑–æ–≤—ã–π —ç–Ω–∫–æ–¥–µ—Ä (–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π)
        base_model = tf.keras.applications.EfficientNetB0(
            include_top=False,
            weights='imagenet',
            input_tensor=inputs,
            pooling='avg'
        )
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Å–ª–æ–∏ (–º–æ–∂–Ω–æ —Ä–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏)
        base_model.trainable = False
        
        # –û–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        x = base_model.output
        x = layers.Dense(512, activation='relu')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(self.dropout_rate)(x)
        
        # –í–µ—Ç–≤—å 1: –†–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–µ—Ü–µ–ø—Ç–∞
        reg_branch = layers.Dense(256, activation='relu')(x)
        reg_branch = layers.BatchNormalization()(reg_branch)
        reg_branch = layers.Dropout(self.dropout_rate * 0.7)(reg_branch)
        reg_branch = layers.Dense(128, activation='relu')(reg_branch)
        reg_branch = layers.Dense(64, activation='relu')(reg_branch)
        
        # –í—ã—Ö–æ–¥ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ - –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º sigmoid –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏–π 0-1)
        regression_output = layers.Dense(
            self.num_regression_outputs,
            activation='sigmoid',
            name='regression_output'
        )(reg_branch)
        
        # –í–µ—Ç–≤—å 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è
        cls_branch = layers.Dense(128, activation='relu')(x)
        cls_branch = layers.BatchNormalization()(cls_branch)
        cls_branch = layers.Dropout(self.dropout_rate * 0.7)(cls_branch)
        cls_branch = layers.Dense(64, activation='relu')(cls_branch)
        
        # –í—ã—Ö–æ–¥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        classification_output = layers.Dense(
            self.num_classes,
            activation='softmax',
            name='classification_output'
        )(cls_branch)
        
        # –°–æ–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = Model(
            inputs=inputs,
            outputs=[regression_output, classification_output],
            name='terrazite_recipe_model'
        )
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        self.compile_model()
        
        logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞")
        return self.model
    
    def compile_model(self) -> None:
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–º –∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –ø–æ—Ç–µ—Ä—å"""
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        optimizer = keras.optimizers.Adam(learning_rate=self.learning_rate)
        
        # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
        losses = {
            'regression_output': 'mse',  # Mean Squared Error –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
            'classification_output': 'categorical_crossentropy'  # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        }
        
        # –í–µ—Å–∞ –ø–æ—Ç–µ—Ä—å (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å)
        loss_weights = {
            'regression_output': 0.7,  # –ë–æ–ª–µ–µ –≤–∞–∂–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–µ—Ü–µ–ø—Ç–∞
            'classification_output': 0.3  # –ú–µ–Ω–µ–µ –≤–∞–∂–µ–Ω —Ç–∏–ø –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è
        }
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
        metrics = {
            'regression_output': [
                'mae',  # Mean Absolute Error
                keras.metrics.RootMeanSquaredError(name='rmse')
            ],
            'classification_output': [
                'accuracy',
                keras.metrics.Precision(name='precision'),
                keras.metrics.Recall(name='recall')
            ]
        }
        
        self.model.compile(
            optimizer=optimizer,
            loss=losses,
            loss_weights=loss_weights,
            metrics=metrics
        )
        
        logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞")
    
    def train(
        self,
        train_data: Tuple[np.ndarray, Dict],
        val_data: Optional[Tuple[np.ndarray, Dict]] = None,
        epochs: int = 50,
        batch_size: int = 32,
        callbacks: Optional[List] = None
    ) -> Dict:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
        Args:
            train_data: –ö–æ—Ä—Ç–µ–∂ (X_train, y_dict_train) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            val_data: –ö–æ—Ä—Ç–µ–∂ (X_val, y_dict_val) –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            callbacks: –°–ø–∏—Å–æ–∫ callback'–æ–≤ Keras
        
        Returns:
            –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        X_train, y_train_dict = train_data
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if val_data is not None:
            X_val, y_val_dict = val_data
            validation_data = (X_val, y_val_dict)
        else:
            validation_data = None
        
        # Callbacks –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if callbacks is None:
            callbacks = self._get_default_callbacks()
        
        logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {len(X_train)} –æ–±—Ä–∞–∑—Ü–∞—Ö")
        logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: epochs={epochs}, batch_size={batch_size}")
        
        # –û–±—É—á–µ–Ω–∏–µ
        self.history = self.model.fit(
            X_train,
            y_train_dict,
            validation_data=validation_data,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        logger.info("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return self.history.history
    
    def predict(self, image: np.ndarray) -> Dict:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–µ—Ü–µ–ø—Ç–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ numpy array (1, H, W, 3)
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏:
            - 'recipe_components': –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            - 'aggregate_type': —Ç–∏–ø –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            - 'confidence': —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        if len(image.shape) == 3:
            image = np.expand_dims(image, axis=0)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        recipe_pred, aggregate_pred = self.model.predict(image, verbose=0)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        recipe_percentages = recipe_pred[0] * 100  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        aggregate_idx = np.argmax(aggregate_pred[0])
        aggregate_confidence = aggregate_pred[0][aggregate_idx] * 100
        
        # –¢–∏–ø—ã –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        aggregate_types = ['–º—Ä–∞–º–æ—Ä', '–∫–≤–∞—Ä—Ü', '–≥—Ä–∞–Ω–∏—Ç', '—Å–ª—é–¥–∞', '–∏–∑–≤–µ—Å—Ç–Ω—è–∫']
        aggregate_type = aggregate_types[aggregate_idx] if aggregate_idx < len(aggregate_types) else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
        
        return {
            'recipe_components': recipe_percentages.tolist(),
            'aggregate_type': aggregate_type,
            'confidence': float(aggregate_confidence),
            'aggregate_probabilities': aggregate_pred[0].tolist()
        }
    
    def evaluate(self, test_data: Tuple[np.ndarray, Dict]) -> Dict:
        """
        –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            test_data: –ö–æ—Ä—Ç–µ–∂ (X_test, y_dict_test) –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –æ—Ü–µ–Ω–∫–∏
        """
        X_test, y_test_dict = test_data
        
        logger.info(f"–û—Ü–µ–Ω–∫–∞ –Ω–∞ {len(X_test)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–∞—Ö")
        
        results = self.model.evaluate(X_test, y_test_dict, verbose=0)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        metrics = {}
        for i, metric_name in enumerate(self.model.metrics_names):
            metrics[metric_name] = results[i]
        
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
        for name, value in metrics.items():
            logger.info(f"  {name}: {value:.4f}")
        
        return metrics
    
    def save_model(self, path: str = 'models/terrazite_model.h5') -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
        Args:
            path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏
        """
        self.model.save(path)
        logger.info(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {path}")
    
    def load_model(self, path: str = 'models/terrazite_model.h5') -> None:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        
        Args:
            path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
        """
        self.model = keras.models.load_model(path)
        logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {path}")
    
    def summary(self) -> None:
        """–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        self.model.summary()
    
    def _get_default_callbacks(self) -> List:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö callback'–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        callbacks = [
            # Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True,
                verbose=1
            ),
            # –£–º–µ–Ω—å—à–µ–Ω–∏–µ learning rate –ø—Ä–∏ –ø–ª–∞—Ç–æ
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-6,
                verbose=1
            ),
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            keras.callbacks.ModelCheckpoint(
                'models/best_terrazite_model.h5',
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            ),
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ TensorBoard
            keras.callbacks.TensorBoard(
                log_dir='logs/tensorboard',
                histogram_freq=1
            ),
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
            keras.callbacks.CSVLogger(
                'logs/training_history.csv'
            )
        ]
        
        return callbacks
    
    def fine_tune(self, unfreeze_layers: int = 50) -> None:
        """
        –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—Ä–∞–∑–º–æ—Ä–æ–∑–∫–∞ —á–∞—Å—Ç–∏ —Å–ª–æ–µ–≤)
        
        Args:
            unfreeze_layers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º—ã—Ö —Å–ª–æ–µ–≤
        """
        logger.info(f"–†–∞–∑–º–æ—Ä–æ–∑–∫–∞ {unfreeze_layers} —Å–ª–æ–µ–≤ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è")
        
        # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —á–∞—Å—Ç—å —Å–ª–æ–µ–≤
        for layer in self.model.layers[-unfreeze_layers:]:
            if not isinstance(layer, layers.BatchNormalization):
                layer.trainable = True
        
        # –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Å –º–µ–Ω—å—à–∏–º learning rate
        self.learning_rate = 1e-5
        self.compile_model()
        
        logger.info("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –¥–æ–æ–±—É—á–µ–Ω–∏—é")


def create_simple_model(input_shape=(224, 224, 3)) -> Model:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è
    
    Args:
        input_shape: –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Returns:
        –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Keras
    """
    inputs = layers.Input(shape=input_shape)
    
    # –ü—Ä–æ—Å—Ç–∞—è CNN –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    x = layers.Conv2D(32, 3, activation='relu')(inputs)
    x = layers.MaxPooling2D(2)(x)
    x = layers.Conv2D(64, 3, activation='relu')(x)
    x = layers.MaxPooling2D(2)(x)
    x = layers.Conv2D(128, 3, activation='relu')(x)
    x = layers.GlobalAveragePooling2D()(x)
    
    # –í—ã—Ö–æ–¥—ã
    regression_output = layers.Dense(15, activation='sigmoid', name='regression_output')(x)
    classification_output = layers.Dense(5, activation='softmax', name='classification_output')(x)
    
    model = Model(inputs=inputs, outputs=[regression_output, classification_output])
    
    model.compile(
        optimizer='adam',
        loss={
            'regression_output': 'mse',
            'classification_output': 'categorical_crossentropy'
        },
        metrics={
            'regression_output': ['mae'],
            'classification_output': ['accuracy']
        }
    )
    
    return model


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ TerraziteRecipeModel")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏
    model = TerraziteRecipeModel()
    
    # –°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å
    model.build_model()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
    print("\nüìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
    model.summary()
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("\nüß™ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    test_image = np.random.rand(1, 224, 224, 3).astype('float32')
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    print("üß† –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏...")
    prediction = model.predict(test_image)
    
    print("\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    print(f"–¢–∏–ø –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è: {prediction['aggregate_type']}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {prediction['confidence']:.1f}%")
    print(f"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {len(prediction['recipe_components'])}")
    
    print("\n‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
