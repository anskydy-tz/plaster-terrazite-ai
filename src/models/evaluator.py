"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π.
"""
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, mean_absolute_error
import tensorflow as tf
import logging
from typing import Dict, List, Tuple, Optional
import json
import os

logger = logging.getLogger(__name__)


class ModelEvaluator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """
    
    def __init__(self, model=None, model_path=None):
        self.model = model
        if model_path and not model:
            self.load_model(model_path)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        plt.style.use('seaborn-v0_8-darkgrid')
        sns.set_palette("husl")
    
    def load_model(self, model_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞."""
        if model_path.endswith('.h5'):
            self.model = tf.keras.models.load_model(model_path)
        else:
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —ç—Ç–æ simple_classifier
            import joblib
            data = joblib.load(model_path)
            self.model = data['model']
        
        logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
    
    def evaluate_classification(
        self,
        X_test: np.ndarray,
        y_test: np.ndarray,
        class_names: List[str],
        save_dir: Optional[str] = None
    ) -> Dict:
        """
        –û—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏.
        
        Args:
            X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            y_test: –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (one-hot encoded)
            class_names: –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
            save_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        logger.info("–û—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if hasattr(self.model, 'predict'):
            # –î–ª—è Keras –º–æ–¥–µ–ª–µ–π
            predictions = self.model.predict(X_test)
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è, –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –≤—ã—Ö–æ–¥
            if isinstance(predictions, list):
                y_pred_proba = predictions[1]  # classification_output
            else:
                y_pred_proba = predictions
            
            y_pred = np.argmax(y_pred_proba, axis=1)
        else:
            # –î–ª—è sklearn –º–æ–¥–µ–ª–µ–π
            y_pred = self.model.predict(X_test)
            y_pred_proba = self.model.predict_proba(X_test) if hasattr(self.model, 'predict_proba') else None
        
        y_true = np.argmax(y_test, axis=1) if len(y_test.shape) > 1 else y_test
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        cm = confusion_matrix(y_true, y_pred)
        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
        self.plot_confusion_matrix(cm, class_names, save_dir)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—à–∏–±–æ–∫
        if save_dir:
            self.plot_misclassified_examples(X_test, y_true, y_pred, class_names, save_dir)
        
        logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å: {report['accuracy']:.2%}")
        logger.info(f"–û—Ç—á–µ—Ç:\n{json.dumps(report, indent=2)}")
        
        return {
            'confusion_matrix': cm.tolist(),
            'classification_report': report,
            'predictions': y_pred.tolist(),
            'true_labels': y_true.tolist()
        }
    
    def evaluate_regression(
        self,
        X_test: np.ndarray,
        y_test: np.ndarray,
        component_names: List[str],
        save_dir: Optional[str] = None
    ) -> Dict:
        """
        –û—Ü–µ–Ω–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏.
        
        Args:
            X_test: –¢–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            y_test: –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            component_names: –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            save_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        logger.info("–û—Ü–µ–Ω–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
        
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        if hasattr(self.model, 'predict'):
            predictions = self.model.predict(X_test)
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è, –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –≤—ã—Ö–æ–¥
            if isinstance(predictions, list):
                y_pred = predictions[0]  # regression_output
            else:
                y_pred = predictions
        else:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏—é")
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        mse_per_component = mean_squared_error(y_test, y_pred, multioutput='raw_values')
        mae_per_component = mean_absolute_error(y_test, y_pred, multioutput='raw_values')
        
        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        total_mse = mean_squared_error(y_test, y_pred)
        total_mae = mean_absolute_error(y_test, y_pred)
        total_rmse = np.sqrt(total_mse)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        if save_dir:
            self.plot_regression_results(y_test, y_pred, component_names, save_dir)
        
        logger.info(f"–û–±—â–∞—è MSE: {total_mse:.4f}")
        logger.info(f"–û–±—â–∞—è MAE: {total_mae:.4f}")
        logger.info(f"–û–±—â–∞—è RMSE: {total_rmse:.4f}")
        
        return {
            'mse_per_component': dict(zip(component_names, mse_per_component.tolist())),
            'mae_per_component': dict(zip(component_names, mae_per_component.tolist())),
            'total_mse': float(total_mse),
            'total_mae': float(total_mae),
            'total_rmse': float(total_rmse),
            'predictions': y_pred.tolist(),
            'true_values': y_test.tolist()
        }
    
    def plot_confusion_matrix(
        self,
        cm: np.ndarray,
        class_names: List[str],
        save_dir: Optional[str] = None
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫."""
        plt.figure(figsize=(10, 8))
        
        # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names
        )
        
        plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
        plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
        plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
        plt.tight_layout()
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            plt.savefig(os.path.join(save_dir, 'confusion_matrix.png'), dpi=300)
            plt.savefig(os.path.join(save_dir, 'confusion_matrix.pdf'))
        
        plt.show()
        plt.close()
    
    def plot_regression_results(
        self,
        y_true: np.ndarray,
        y_pred: np.ndarray,
        component_names: List[str],
        save_dir: Optional[str] = None
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏."""
        num_components = y_true.shape[1]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        max_components = min(10, num_components)
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É –≥—Ä–∞—Ñ–∏–∫–æ–≤
        fig, axes = plt.subplots(2, (max_components + 1) // 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i in range(max_components):
            ax = axes[i]
            
            # Scatter plot –∏—Å—Ç–∏–Ω–Ω—ã—Ö vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            ax.scatter(y_true[:, i], y_pred[:, i], alpha=0.5)
            
            # –õ–∏–Ω–∏—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            min_val = min(y_true[:, i].min(), y_pred[:, i].min())
            max_val = max(y_true[:, i].max(), y_pred[:, i].max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='–ò–¥–µ–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ')
            
            ax.set_xlabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
            ax.set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
            ax.set_title(f'{component_names[i]}')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –æ—Å–∏
        for i in range(max_components, len(axes)):
            fig.delaxes(axes[i])
        
        plt.suptitle('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–µ—Ü–µ–ø—Ç–∞', fontsize=16)
        plt.tight_layout()
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            plt.savefig(os.path.join(save_dir, 'regression_results.png'), dpi=300)
            plt.savefig(os.path.join(save_dir, 'regression_results.pdf'))
        
        plt.show()
        plt.close()
    
    def plot_misclassified_examples(
        self,
        X_test: np.ndarray,
        y_true: np.ndarray,
        y_pred: np.ndarray,
        class_names: List[str],
        save_dir: str,
        num_examples: int = 5
    ):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –æ—à–∏–±–æ–∫
        misclassified_idx = np.where(y_true != y_pred)[0]
        
        if len(misclassified_idx) == 0:
            logger.info("–ù–µ—Ç –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
            return
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
        num_examples = min(num_examples, len(misclassified_idx))
        selected_idx = misclassified_idx[:num_examples]
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig, axes = plt.subplots(1, num_examples, figsize=(15, 4))
        if num_examples == 1:
            axes = [axes]
        
        for i, idx in enumerate(selected_idx):
            ax = axes[i]
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if len(X_test.shape) == 4:
                img = X_test[idx]
                if img.shape[-1] == 3:
                    ax.imshow(img)
                else:
                    ax.imshow(img, cmap='gray')
            else:
                # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                ax.text(0.5, 0.5, f"–û—à–∏–±–∫–∞\n{class_names[y_true[idx]]} ‚Üí {class_names[y_pred[idx]]}",
                       ha='center', va='center', fontsize=12)
            
            ax.set_title(f"–ò—Å—Ç–∏–Ω–Ω—ã–π: {class_names[y_true[idx]]}\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π: {class_names[y_pred[idx]]}")
            ax.axis('off')
        
        plt.suptitle(f'–ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ({len(misclassified_idx)} –≤—Å–µ–≥–æ)', fontsize=14)
        plt.tight_layout()
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            plt.savefig(os.path.join(save_dir, 'misclassified_examples.png'), dpi=300)
            plt.savefig(os.path.join(save_dir, 'misclassified_examples.pdf'))
        
        plt.show()
        plt.close()
    
    def generate_report(
        self,
        classification_results: Dict,
        regression_results: Dict,
        save_path: str = 'reports/evaluation_report.json'
    ):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± –æ—Ü–µ–Ω–∫–µ."""
        report = {
            'timestamp': np.datetime64('now').astype(str),
            'classification': classification_results,
            'regression': regression_results,
            'summary': {
                'classification_accuracy': classification_results['classification_report']['accuracy'],
                'regression_mse': regression_results['total_mse'],
                'regression_mae': regression_results['total_mae']
            }
        }
        
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {save_path}")
        return report


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ModelEvaluator")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    num_samples = 100
    X_test = np.random.rand(num_samples, 224, 224, 3)
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: 5 –∫–ª–∞—Å—Å–æ–≤
    y_cls_true = np.random.randint(0, 5, size=num_samples)
    y_cls_test = tf.keras.utils.to_categorical(y_cls_true, 5)
    
    # –†–µ–≥—Ä–µ—Å—Å–∏—è: 15 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    y_reg_test = np.random.rand(num_samples, 15)
    
    class_names = ['–º—Ä–∞–º–æ—Ä', '–∫–≤–∞—Ä—Ü', '–≥—Ä–∞–Ω–∏—Ç', '—Å–ª—é–¥–∞', '–∏–∑–≤–µ—Å—Ç–Ω—è–∫']
    component_names = [f'–∫–æ–º–ø–æ–Ω–µ–Ω—Ç_{i}' for i in range(15)]
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –º–æ–¥–µ–ª–∏ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å)
    from .terrazite_model import TerraziteRecipeModel
    model = TerraziteRecipeModel()
    model.build_model()
    
    # –°–æ–∑–¥–∞–µ–º evaluator
    evaluator = ModelEvaluator(model=model)
    
    # –û—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("–û—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
    cls_results = evaluator.evaluate_classification(
        X_test[:10],  # –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 10 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        y_cls_test[:10],
        class_names,
        save_dir='test_evaluation'
    )
    
    # –û—Ü–µ–Ω–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    print("\n–û—Ü–µ–Ω–∫–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
    reg_results = evaluator.evaluate_regression(
        X_test[:10],
        y_reg_test[:10],
        component_names,
        save_dir='test_evaluation'
    )
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = evaluator.generate_report(cls_results, reg_results, 'test_evaluation/report.json')
    
    print("\n‚úÖ ModelEvaluator –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
